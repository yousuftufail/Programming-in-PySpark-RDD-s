# Programming-in-PySpark-RDD-s

Two ways to construct RDD in pyspark are presented. Both the examples are taken from datacamp.

# important libraries 

import findspark

findspark.init("path-to-hadoop3.2")

pyspark.SparkConf

pyspark.context.SparkContext

pyspark.sql.SparkSession

